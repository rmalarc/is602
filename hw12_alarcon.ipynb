{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS602: IPython Part 2  \n",
    "### Author: Mauricio Alarcon\n",
    "### November 25, 2015\n",
    "\n",
    "\n",
    "* Take your solution from Homework 11 and complete the Monte Carlo step (step 6) in parallel.  There are many ways you can go about doing this, and I'm not looking for anything too complicated.  If you can get multiple processes crunching the data together, that is great.  Using IPythonâ€™s built-in tools would be a great method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's pre-process the dataset and obtain the parameters for the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malarcon\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "apple_2011 = pd.read_csv('apple.2011.csv')\n",
    "\n",
    "apple_2011.columns = ['date', 'last_price','pct_change']\n",
    "apple_2011[['pct_change']] = apple_2011[['pct_change']].convert_objects(convert_numeric=True)\n",
    "apple_2011.head()\n",
    "\n",
    "apple_mean = apple_2011['pct_change'].mean()\n",
    "apple_sd = apple_2011['pct_change'].std()\n",
    "apple_last_price = float(apple_2011['last_price'].tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0009573552071713143, 0.016520556298411322, 405.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(apple_mean,apple_sd,apple_last_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the simulation code that needs to be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulation_functions = '''\n",
    "from functools import reduce\n",
    "import operator\n",
    "import numpy\n",
    "\n",
    "\n",
    "def gaussian_daily_change ( mean, sd, days ):\n",
    "    return(numpy.random.normal(mean,sd,days))\n",
    "\n",
    "def cummulative_pct_change(mean,sd,days):\n",
    "    daily_pct_change = gaussian_daily_change(mean, sd, days)\n",
    "    total_pct_change = reduce(operator.mul, daily_pct_change+1, 1)\n",
    "    return (total_pct_change)\n",
    "\n",
    "def repeat_price_est_n_times(price, mean, sd, days, n):\n",
    "    prices = [1]*n\n",
    "    return (map(lambda x: float(cummulative_pct_change(mean, sd, days)*price), prices))\n",
    "'''\n",
    "\n",
    "simulation_code = simulation_functions + '''\n",
    "\n",
    "output = repeat_price_est_n_times({}, {}, {}, {}, {})\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the timing for your solution in homework 11 and this parallel solution.  This is similar to what you did in homeworks 6 and 7.  Ideally, you'll see some speed improvement.  The amount you see will largely be based the capabilities of your hardware, and less on the software implementation.  There is additional overhead for running an operation in parallel, so speed gains will be more obvious with a larger number of calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time the execution time for a total of 4,000 experiment repetitions as a single process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "execute_this = simulation_code.format(apple_last_price,apple_mean,apple_sd,20,4000)\n",
    "timeit.timeit(execute_this, number=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how long it takes to run the same 4,000 experiments over a cluster of four parallel processes at 1000 experiments per process. Please note that the cluster has been started by executing: ```ipcluster start -n 4```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallelized_code = '''\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "\n",
    "clients = ipp.Client()\n",
    "\n",
    "clients.block = True\n",
    "\n",
    "print clients.ids\n",
    "\n",
    "dview = clients.direct_view()\n",
    "\n",
    "simulation_code = \\'\\'\\'\n",
    "{}\n",
    "\\'\\'\\'\n",
    "\n",
    "dview.execute(simulation_code.format({}, {}, {}, {}, {}))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execute_this = simulation_code.format(apple_last_price,apple_mean,apple_sd,20,1000)\n",
    "timeit.timeit(execute_this, number=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see from the results, spreading the load over 4 proceses results in an equivalent execution time reduction**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
